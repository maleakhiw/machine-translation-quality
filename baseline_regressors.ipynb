{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline Regressors",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "omEQHVdOS61G"
      },
      "source": [
        "# Baseline Word Embeddings with Regressors\n",
        "\n",
        "**Author**: Maleakhi Wijaya, Faidon Mitzalis, Harry Coppock  \n",
        "**Date**: 20 February 2020\n",
        "\n",
        "The file contains the following items:\n",
        "- Baseline word embeddings techniques mentioned in the report (Word2Vec & GloVe)\n",
        "- Regressors\n",
        "  - Random Forest\n",
        "  - Support Vector Machine (SVR)\n",
        "  - Feed Forward Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3obhUYW5ptUS"
      },
      "source": [
        "## Baseline Word Embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOEKmhjPkcP7",
        "colab_type": "text"
      },
      "source": [
        "### Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oWPvIbekbP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "255cff60-9195-46c7-a88c-7fe0fed38601"
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "from os.path import exists\n",
        "import torchtext\n",
        "import spacy\n",
        "import numpy as np\n",
        "import torch\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import string\n",
        "import jieba\n",
        "import gensim \n",
        "from torchtext import data\n",
        "from sklearn.svm import SVR\n",
        "from scipy.stats.stats import pearsonr\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import logging\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import time\n",
        "import torch.optim as optim"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.11.15)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OE9wypehaLrZ"
      },
      "source": [
        "### Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_5y34iNipyr3",
        "colab": {}
      },
      "source": [
        "if not exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RlXMiqJXq8fy",
        "outputId": "f8394f9a-7b81-4cae-de20-97c1b60b820f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# English-Chinese\n",
        "# Checking Data\n",
        "print(\"---EN-ZH---\")\n",
        "print()\n",
        "\n",
        "with open(\"./train.enzh.src\", \"r\") as enzh_src:\n",
        "  print(\"Source: \",enzh_src.readline())\n",
        "with open(\"./train.enzh.mt\", \"r\") as enzh_mt:\n",
        "  print(\"Translation: \",enzh_mt.readline())\n",
        "with open(\"./train.enzh.scores\", \"r\") as enzh_scores:\n",
        "  print(\"Score: \",enzh_scores.readline())"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---EN-ZH---\n",
            "\n",
            "Source:  The last conquistador then rides on with his sword drawn.\n",
            "\n",
            "Translation:  最后的征服者骑着他的剑继续前进.\n",
            "\n",
            "Score:  -1.5284005772625449\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QsKYMxCSolrx"
      },
      "source": [
        "### Pre-processing English with GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8lc4rdJnrE_Q",
        "outputId": "91137dd9-6665-43f7-e4ba-ef0b83b01249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Downloading spacy models for english\n",
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz#egg=en_core_web_md==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\n",
            "\u001b[38;5;1m✘ Link 'en300' already exists\u001b[0m\n",
            "To overwrite an existing link, use the --force flag\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fx3Ja9zWFDj2",
        "colab": {}
      },
      "source": [
        "# Embeddings\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=100)\n",
        "\n",
        "# tokenizer model\n",
        "nlp_en =spacy.load('en300')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2BUi2QiCIi9y",
        "outputId": "885a85ba-b849-4e72-81a8-d1bebb3e1d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Function related to generated English embeddings\n",
        "# Setup stop words\n",
        "download('stopwords') #stopwords dictionary, run once\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(sentence, nlp):\n",
        "    \"\"\"\n",
        "    Pre-process sentence by normalisation, tokenizing, removing stop words, and only restrict \n",
        "    string to alphabetic characters only.\n",
        "\n",
        "    Parameters:\n",
        "    - sentence: sentence in a corpus\n",
        "    - nlp: tokenizer used\n",
        "\n",
        "    Returns:\n",
        "    - list of words that has been preprocess\n",
        "    \"\"\"\n",
        "    text = sentence.lower()\n",
        "    doc = [token.lemma_ for token in  nlp.tokenizer(text)]\n",
        "    doc = [word for word in doc if word not in stop_words_en]\n",
        "    doc = [word for word in doc if word.isalpha()]\n",
        "    return doc\n",
        "\n",
        "def get_word_vector(embeddings, word):\n",
        "    \"\"\"\n",
        "    Get vector representation for a given word (word embedding).\n",
        "\n",
        "    Parameters:\n",
        "    - embeddings: embedding object\n",
        "    - word: string (word) to be converted to vector representation\n",
        "    \"\"\"\n",
        "    try:\n",
        "      vec = embeddings.vectors[embeddings.stoi[word]]\n",
        "      return vec\n",
        "    except KeyError:\n",
        "      pass\n",
        "\n",
        "def get_sentence_vector(embeddings, line):\n",
        "    \"\"\"\n",
        "    Get sentence embedding by averaging word embeddings in sentence.\n",
        "\n",
        "    Parameters:\n",
        "    - embeddings: embedding object\n",
        "    - line: sentence (list of words)\n",
        "\n",
        "    Returns:\n",
        "    - sentence embedding\n",
        "    \"\"\"\n",
        "    vectors = []\n",
        "    for w in line:\n",
        "        emb = get_word_vector(embeddings,w)\n",
        "        \n",
        "        # Only add when word is in the dictionary\n",
        "        if emb is not None:\n",
        "            vectors.append(emb)\n",
        "   \n",
        "    return torch.mean(torch.stack(vectors), dim=0)\n",
        "\n",
        "\n",
        "def get_embeddings(f, embeddings, lang):\n",
        "    \"\"\"\n",
        "    Main methods to open file, and perform above functions.\n",
        "\n",
        "    Parameters\n",
        "    - f: file name\n",
        "    - embeddings: embeddings object\n",
        "    - lang: language\n",
        "\n",
        "    Returns:\n",
        "    - list of sentence embedding\n",
        "    \"\"\"\n",
        "    file = open(f) \n",
        "    lines = file.readlines() \n",
        "    sentences_vectors =[]\n",
        "\n",
        "    for l in lines:\n",
        "        sentence= preprocess(l,lang)\n",
        "        try:\n",
        "            vec = get_sentence_vector(embeddings,sentence)\n",
        "            sentences_vectors.append(vec)\n",
        "        except:\n",
        "            sentences_vectors.append(np.zeros((100,)))\n",
        "\n",
        "    return sentences_vectors"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f4JnbxSaaasu"
      },
      "source": [
        "### Pre-processing Chinese with Word2Vec\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-jW3S2-rs6BV",
        "outputId": "2d57f4c3-a107-4453-b55e-3fc244b147b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "!wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
        "\n",
        "!wget -O zh.zip http://vectors.nlpl.eu/repository/20/35.zip\n",
        "\n",
        "!unzip zh.zip "
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-27 21:43:03--  https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘chinese_stop_words.txt’\n",
            "\n",
            "\rchinese_stop_words.     [<=>                 ]       0  --.-KB/s               \rchinese_stop_words.     [ <=>                ] 419.55K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-02-27 21:43:04 (7.84 MB/s) - ‘chinese_stop_words.txt’ saved [429623]\n",
            "\n",
            "--2020-02-27 21:43:05--  http://vectors.nlpl.eu/repository/20/35.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1458485917 (1.4G) [application/zip]\n",
            "Saving to: ‘zh.zip’\n",
            "\n",
            "zh.zip              100%[===================>]   1.36G  22.8MB/s    in 67s     \n",
            "\n",
            "2020-02-27 21:44:13 (20.8 MB/s) - ‘zh.zip’ saved [1458485917/1458485917]\n",
            "\n",
            "Archive:  zh.zip\n",
            "replace LIST? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace meta.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uDUbXQ4aMv1K",
        "outputId": "da28b787-6645-4d4b-877a-3148efac9b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Load pre-trained word2vec using gensim\n",
        "wv_from_bin = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True) "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-LA9N1zgsSQl",
        "colab": {}
      },
      "source": [
        "# Function related to generating chinese embeddings.\n",
        "stop_words = [line.rstrip() for line in open('./chinese_stop_words.txt',\"r\", encoding=\"utf-8\")]\n",
        "\n",
        "def get_sentence_vector_zh(line):\n",
        "    \"\"\"\n",
        "    Generate sentence embeddings.\n",
        "\n",
        "    Parameters:\n",
        "    - line: list of words\n",
        "    \n",
        "    Returns:\n",
        "    - sentence embeddings\n",
        "    \"\"\"\n",
        "    vectors = []\n",
        "    for w in line:\n",
        "        try:\n",
        "            emb = wv_from_bin[w]\n",
        "            vectors.append(emb)\n",
        "        except:\n",
        "            pass # Do not add if the word is out of vocabulary\n",
        "    if vectors:\n",
        "        vectors = np.array(vectors)\n",
        "        return np.mean(vectors, axis=0)  \n",
        "    else:\n",
        "        return np.zeros((100,))\n",
        "\n",
        "def processing_zh(sentence):\n",
        "    \"\"\"\n",
        "    Tokenization and preprocessing.\n",
        "\n",
        "    Parameters:\n",
        "    - sentence: string of words\n",
        "\n",
        "    Returns:\n",
        "    - list of tokens\n",
        "    \"\"\"\n",
        "    seg_list = jieba.lcut(sentence,cut_all=True)\n",
        "    doc = [word for word in seg_list if word not in stop_words]\n",
        "    docs = [e for e in doc if e.isalnum()]\n",
        "    return docs\n",
        "\n",
        "def get_sentence_embeddings_zh(f):\n",
        "    \"\"\"\n",
        "    Main function that call functions from above.\n",
        "\n",
        "    Parameters:\n",
        "    - f: file name\n",
        "\n",
        "    Returns:\n",
        "    - list of sentence embeddings\n",
        "    \"\"\"\n",
        "    file = open(f) \n",
        "    lines = file.readlines() \n",
        "    sentences_vectors =[]\n",
        "    for l in lines:\n",
        "        sent  = processing_zh(l)\n",
        "        vec = get_sentence_vector_zh(sent)\n",
        "\n",
        "        if vec is not None:\n",
        "            sentences_vectors.append(vec)\n",
        "        else:\n",
        "            print(l)\n",
        "    \n",
        "    return sentences_vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6zVjor64tR8D",
        "colab": {}
      },
      "source": [
        "# Get sentence embeddings\n",
        "zh_train_mt = get_sentence_embeddings_zh(\"./train.enzh.mt\")\n",
        "zh_train_src = get_embeddings(\"./train.enzh.src\",glove,nlp_en)\n",
        "f_train_scores = open(\"./train.enzh.scores\",'r')\n",
        "zh_train_scores = f_train_scores.readlines()\n",
        "\n",
        "zh_val_src = get_embeddings(\"./dev.enzh.src\",glove,nlp_en)\n",
        "zh_val_mt = get_sentence_embeddings_zh(\"./dev.enzh.mt\")\n",
        "f_val_scores = open(\"./dev.enzh.scores\",'r')\n",
        "zh_val_scores = f_val_scores.readlines()\n",
        "\n",
        "zh_test_mt = get_sentence_embeddings_zh(\"./test.enzh.mt\")\n",
        "zh_test_src = get_embeddings(\"./test.enzh.src\",glove,nlp_en)\n",
        "\n",
        "# Convert into required format for input to the statistical regressors\n",
        "zh_train_src = np.array([arr.tolist() for arr in zh_train_src])\n",
        "zh_train_mt = np.array([arr.tolist() for arr in zh_train_mt])\n",
        "zh_val_src = np.array([arr.tolist() for arr in zh_val_src])\n",
        "zh_val_mt = np.array([arr.tolist() for arr in zh_val_mt])\n",
        "zh_test_src = np.array([arr.tolist() for arr in zh_test_src])\n",
        "zh_test_mt = np.array([arr.tolist() for arr in zh_test_mt])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N-pXbaJzExaE",
        "outputId": "3c1c5bff-64cf-4d4c-b174-91eeb6f7f313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Ensure the right number of training data, testing data\n",
        "print(f\"Training mt: {len(zh_train_mt)} Training src: {len(zh_train_src)}\")\n",
        "print()\n",
        "print(f\"Validation mt: {len(zh_val_mt)} Validation src: {len(zh_val_src)}\")\n",
        "print()\n",
        "print(f\"Test mt: {len(zh_test_mt)} Test src: {len(zh_test_src)}\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training mt: 7000 Training src: 7000\n",
            "\n",
            "Validation mt: 1000 Validation src: 1000\n",
            "\n",
            "Test mt: 1000 Test src: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHlyyO3JqXJ1",
        "colab_type": "text"
      },
      "source": [
        "### Concatenate GloVe and Word2Vec\n",
        "\n",
        "The cell below are responsible to generate the baseline word embeddings of 200 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ljBHJpa9ATNf",
        "colab": {}
      },
      "source": [
        "# Generate X_train embeddings\n",
        "X_train = np.concatenate((zh_train_src, zh_train_mt), axis=1)\n",
        "X_train = X_train.flatten()\n",
        "X_train_zh = X_train.reshape(7000, 200)\n",
        "\n",
        "# Generate X_val embeddings\n",
        "X_val = np.concatenate((zh_val_src, zh_val_mt), axis=1)\n",
        "X_val = X_val.flatten()\n",
        "X_val_zh = X_val.reshape(1000, 200)\n",
        "\n",
        "# Generate X_test embeddings\n",
        "X_test = np.concatenate((zh_test_src, zh_test_mt), axis=1)\n",
        "X_test = X_test.flatten()\n",
        "X_test_zh = X_test.reshape(1000, 200)\n",
        "\n",
        "# Scores\n",
        "train_scores = np.array(zh_train_scores).astype(float)\n",
        "y_train_zh =train_scores\n",
        "\n",
        "val_scores = np.array(zh_val_scores).astype(float)\n",
        "y_val_zh =val_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "luNEyefram7Z"
      },
      "source": [
        "## SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "USalvKtRAvQv",
        "colab": {}
      },
      "source": [
        "def rmse(predictions, targets):\n",
        "    \"\"\"\n",
        "    Calculate root mean square.\n",
        "    \"\"\"\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bf_aJK0QK8jx",
        "outputId": "f22f6ea0-f16a-4bd8-d14e-a615081d6cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Run SVM with different kernels\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print(\"-\"*50)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear\n",
            "RMSE: 0.9044962563186333 Pearson 0.3017781690203462\n",
            "--------------------------------------------------\n",
            "poly\n",
            "RMSE: 0.8990697909416231 Pearson 0.3032902746054339\n",
            "--------------------------------------------------\n",
            "rbf\n",
            "RMSE: 0.8900985622788053 Pearson 0.3403404558003603\n",
            "--------------------------------------------------\n",
            "sigmoid\n",
            "RMSE: 7.152607007355879 Pearson -0.03977439348067312\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJt7xCJWsSrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict (run this to make predictions to test)\n",
        "clf_zh = SVR(kernel='rbf')\n",
        "clf_zh.fit(X_train_zh, y_train_zh)\n",
        "\n",
        "predictions_zh = clf_zh.predict(X_test_zh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wtg69eGbgmHI"
      },
      "source": [
        "## Random Tree Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6wEoExkggqHG",
        "outputId": "8a64647e-d136-41b5-de79-5296e5d7ec6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Random forest training and evaluation using validation\n",
        "rf = RandomForestRegressor(n_estimators = 100, random_state = 666)\n",
        "rf.fit(X_train_zh, y_train_zh);\n",
        "predictions = rf.predict(X_val_zh)\n",
        "\n",
        "pearson = pearsonr(y_val_zh, predictions)\n",
        "print('RMSE:', rmse(predictions,y_val_zh))\n",
        "print(f\"Pearson {pearson[0]}\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.8830922225183105\n",
            "Pearson 0.24458603542177823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbFgpFEsruM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict (run this to make predictions to test)\n",
        "predictions_zh = rf.predict(X_test_zh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tst89MRTW_Td",
        "colab_type": "text"
      },
      "source": [
        "## Feed Forward Neural Network\n",
        "\n",
        "This section contains code for feed forward neural network along with code to get the appropriate input for a neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKa90pZ6sXg1",
        "colab_type": "text"
      },
      "source": [
        "### Setup & Input Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB7R-JlYXMM4",
        "colab_type": "code",
        "outputId": "5a1aafd8-d173-4bde-8ead-0b449e1a4c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Enable GPU\n",
        "print('Torch version: {}, CUDA: {}'.format(torch.__version__, torch.version.cuda))\n",
        "cuda_available = torch.cuda.is_available()\n",
        "if not torch.cuda.is_available():\n",
        "  print('WARNING: You may want to change the runtime to GPU!')\n",
        "  device = 'cpu'\n",
        "else:\n",
        "  device = 'cuda:0'"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch version: 1.4.0, CUDA: 10.1\n",
            "WARNING: You may want to change the runtime to GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9goaqCRXPcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\" Set all seeds to make results reproducible (deterministic mode).\n",
        "        When seed is a false-y value or not supplied, disables deterministic mode. \"\"\"\n",
        "\n",
        "    if seed:\n",
        "        logging.info(f\"Running in deterministic mode with seed {seed}\")\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        np.random.seed(seed)\n",
        "    else:\n",
        "        logging.info(f\"Running in non-deterministic mode\")\n",
        "\n",
        "set_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTn-rMB_XQ1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert data from numpy -> torch tensor\n",
        "X_train_zh = torch.Tensor(X_train_zh) \n",
        "X_val_zh = torch.Tensor(X_val_zh)\n",
        "\n",
        "y_train_zh = torch.Tensor(y_train_zh)\n",
        "y_val_zh = torch.Tensor(y_val_zh)\n",
        "\n",
        "X_test_zh = torch.Tensor(X_test_zh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GG0SlpTs2k3",
        "colab_type": "text"
      },
      "source": [
        "### Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC_VK_wmXUYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FFNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Vanilla Feed Forward Neural Network.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(FFNN, self).__init__()\n",
        "\n",
        "        # Try 4 linear layers\n",
        "        self.fc1 = nn.Linear(200, 800)\n",
        "        self.fc2 = nn.Linear(800, 200)\n",
        "        self.fc3 = nn.Linear(200, 100)\n",
        "        self.fc4 = nn.Linear(100, 1)\n",
        "\n",
        "        # Loss function\n",
        "        self.loss = nn.MSELoss()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def get_batches(self, X, y=None, batch_size=64, test=False):\n",
        "        \"\"\"\n",
        "        Method to separate data into batches.\n",
        "        \"\"\"\n",
        "        # Get the number of training samples\n",
        "        n_samples = X.size(0)\n",
        "        n_batches = n_samples // batch_size\n",
        "        n_samples = n_batches * batch_size\n",
        "        \n",
        "        # If it is not test, then shuffle the order\n",
        "        if not test:\n",
        "            permutation = torch.randperm(n_samples) # Return indices randomly ordered\n",
        "\n",
        "            # Shuffle the dataset\n",
        "            X = X[permutation, :]\n",
        "            y = y[permutation]\n",
        "\n",
        "            # Get this into batches\n",
        "            X_batch = X.view(n_batches, batch_size, X.size(1))\n",
        "            y_batch = y.view(n_batches, batch_size)\n",
        "\n",
        "            return X_batch, y_batch\n",
        "        else:\n",
        "            order = torch.arange(0, n_samples).long()\n",
        "            X = X[order, :]\n",
        "            \n",
        "            X_batch = X.view(n_batches, batch_size, X.size(1))\n",
        "\n",
        "            return X_batch\n",
        "    \n",
        "    def train_model(self, optim, X_train, y_train, X_val, y_val, X_test, n_epochs=10, batch_size=64, shuffle=False):\n",
        "        \"\"\"\n",
        "        Train FFNN model for n epochs.\n",
        "        \"\"\"\n",
        "        # Get batches for training data\n",
        "        X_batches, y_batches = self.get_batches(X_train, y_train, batch_size, False)\n",
        "\n",
        "        # Iterate over n epochs\n",
        "        for eidx in range(1, n_epochs+1):\n",
        "            self.train() # enable training mode\n",
        "\n",
        "            # Shuffle batch order\n",
        "            if shuffle:\n",
        "                batch_order = torch.randperm(X_batches.size(0))\n",
        "            else:\n",
        "                batch_order = torch.arange(X_batches.size(0))\n",
        "            \n",
        "            # Start training\n",
        "            for iter_count, idx in enumerate(batch_order):\n",
        "                X_batch = X_batches[idx].to(device)\n",
        "                y_batch = y_batches[idx].to(device)\n",
        "\n",
        "                # Clear gradient\n",
        "                optim.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                preds = self.forward(X_batch)\n",
        "                loss = self.loss(preds.view(-1), y_batch.view(-1))\n",
        "\n",
        "                # Backward pass\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "\n",
        "            # At the end of the epochs, evaluate on dev set\n",
        "            rmse, pearson = self.evaluate(X_val, y_val, batch_size=batch_size)\n",
        "            print(f\"[Epoch {eidx:<3}] ended with valid rmse: {rmse:6.2f}, pearson: {pearson[0]:6.3f}\")\n",
        "            self.test_model(X_test, batch_size=10, epoch=eidx)\n",
        "\n",
        "    def evaluate(self, X_val, y_val, batch_size=64):\n",
        "        \"\"\"\n",
        "        Evaluate pearson and rmse (on test or validation).\n",
        "        \"\"\"\n",
        "        # Initialise result tensor\n",
        "        out = torch.tensor([])\n",
        "\n",
        "        # Split into batches\n",
        "        X_batches, y_batches = self.get_batches(X_val, y_val, batch_size)\n",
        "\n",
        "        self.eval() # evaluation mode\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch_order = torch.arange(X_batches.size(0))\n",
        "\n",
        "            for iter_count, idx in enumerate(batch_order):\n",
        "                X_batch = X_batches[idx].to(device)\n",
        "                \n",
        "                results = (self.forward(X_batch)).cpu()\n",
        "                temp = torch.cat((out, results), 0)\n",
        "                out = temp\n",
        "        \n",
        "        # Normalise by the number of tokens in the test set\n",
        "        RMSE = mean_squared_error(y_batches.view(-1), out.view(-1), squared=False)\n",
        "        pears = pearsonr(y_batches.view(-1), out.view(-1))\n",
        "\n",
        "        self.train() # switch back to training mode\n",
        "\n",
        "        # Return metrics\n",
        "        return RMSE, pears\n",
        "    \n",
        "    def test_model(self, X_test, batch_size=10, epoch=1):\n",
        "        \"\"\"\n",
        "        Test model and generate text files.\n",
        "        \"\"\"\n",
        "        # Initialise results tensor\n",
        "        out = torch.tensor([])\n",
        "\n",
        "        # Split tokens into batches\n",
        "        X_batches = self.get_batches(X_test, batch_size=batch_size, test=True)\n",
        "\n",
        "        # Evaluation mode\n",
        "        self.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch_order = torch.arange(X_batches.size(0))\n",
        "\n",
        "            for iter_count, idx in enumerate(batch_order):\n",
        "                X_batch = X_batches[idx].to(device)\n",
        "\n",
        "                # Get results\n",
        "                results = (self.forward(X_batch)).cpu()\n",
        "                temp = torch.cat((out, results), 0)\n",
        "                out = temp\n",
        "        \n",
        "        # Write scores to text file for predictions every epochs\n",
        "        path = \"/content/drive/My Drive/Colab Notebooks/NLP_group/en-zh/predictions_new\"\\\n",
        "              + str(epoch) + \".txt\"\n",
        "        np.savetxt(path,out.numpy())\n",
        "    \n",
        "        # Switch back to training mode\n",
        "        self.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKcSeDGaXWEp",
        "colab_type": "code",
        "outputId": "982f43aa-a887-4de7-b1dd-eabe79ab6ddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "# Create model\n",
        "model = FFNN()\n",
        "model = model.to(device)\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = BertAdam(model.parameters(), lr=2e-5, warmup=.1)\n",
        "\n",
        "# Train the model for 50 epochs\n",
        "model.train_model(optimizer, X_train_zh, y_train_zh, X_val_zh, y_val_zh, X_test_zh, n_epochs=50)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:pytorch_pretrained_bert.optimization:t_total value of -1 results in schedule not being applied\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Epoch 2  ] ended with valid rmse:   0.87, pearson:  0.270\n",
            "[Epoch 3  ] ended with valid rmse:   0.86, pearson:  0.291\n",
            "[Epoch 4  ] ended with valid rmse:   0.86, pearson:  0.305\n",
            "[Epoch 5  ] ended with valid rmse:   0.85, pearson:  0.314\n",
            "[Epoch 6  ] ended with valid rmse:   0.85, pearson:  0.322\n",
            "[Epoch 7  ] ended with valid rmse:   0.85, pearson:  0.327\n",
            "[Epoch 8  ] ended with valid rmse:   0.85, pearson:  0.331\n",
            "[Epoch 9  ] ended with valid rmse:   0.85, pearson:  0.334\n",
            "[Epoch 10 ] ended with valid rmse:   0.85, pearson:  0.336\n",
            "[Epoch 11 ] ended with valid rmse:   0.85, pearson:  0.338\n",
            "[Epoch 12 ] ended with valid rmse:   0.84, pearson:  0.339\n",
            "[Epoch 13 ] ended with valid rmse:   0.84, pearson:  0.340\n",
            "[Epoch 14 ] ended with valid rmse:   0.84, pearson:  0.341\n",
            "[Epoch 15 ] ended with valid rmse:   0.84, pearson:  0.342\n",
            "[Epoch 16 ] ended with valid rmse:   0.84, pearson:  0.342\n",
            "[Epoch 17 ] ended with valid rmse:   0.84, pearson:  0.343\n",
            "[Epoch 18 ] ended with valid rmse:   0.85, pearson:  0.343\n",
            "[Epoch 19 ] ended with valid rmse:   0.85, pearson:  0.343\n",
            "[Epoch 20 ] ended with valid rmse:   0.85, pearson:  0.342\n",
            "[Epoch 21 ] ended with valid rmse:   0.85, pearson:  0.342\n",
            "[Epoch 22 ] ended with valid rmse:   0.85, pearson:  0.341\n",
            "[Epoch 23 ] ended with valid rmse:   0.85, pearson:  0.341\n",
            "[Epoch 24 ] ended with valid rmse:   0.85, pearson:  0.340\n",
            "[Epoch 25 ] ended with valid rmse:   0.85, pearson:  0.340\n",
            "[Epoch 26 ] ended with valid rmse:   0.85, pearson:  0.339\n",
            "[Epoch 27 ] ended with valid rmse:   0.85, pearson:  0.338\n",
            "[Epoch 28 ] ended with valid rmse:   0.85, pearson:  0.337\n",
            "[Epoch 29 ] ended with valid rmse:   0.85, pearson:  0.336\n",
            "[Epoch 30 ] ended with valid rmse:   0.85, pearson:  0.335\n",
            "[Epoch 31 ] ended with valid rmse:   0.86, pearson:  0.333\n",
            "[Epoch 32 ] ended with valid rmse:   0.86, pearson:  0.332\n",
            "[Epoch 33 ] ended with valid rmse:   0.86, pearson:  0.330\n",
            "[Epoch 34 ] ended with valid rmse:   0.86, pearson:  0.329\n",
            "[Epoch 35 ] ended with valid rmse:   0.86, pearson:  0.327\n",
            "[Epoch 36 ] ended with valid rmse:   0.86, pearson:  0.326\n",
            "[Epoch 37 ] ended with valid rmse:   0.86, pearson:  0.324\n",
            "[Epoch 38 ] ended with valid rmse:   0.87, pearson:  0.323\n",
            "[Epoch 39 ] ended with valid rmse:   0.87, pearson:  0.321\n",
            "[Epoch 40 ] ended with valid rmse:   0.87, pearson:  0.319\n",
            "[Epoch 41 ] ended with valid rmse:   0.87, pearson:  0.318\n",
            "[Epoch 42 ] ended with valid rmse:   0.87, pearson:  0.316\n",
            "[Epoch 43 ] ended with valid rmse:   0.87, pearson:  0.315\n",
            "[Epoch 44 ] ended with valid rmse:   0.87, pearson:  0.313\n",
            "[Epoch 45 ] ended with valid rmse:   0.88, pearson:  0.312\n",
            "[Epoch 46 ] ended with valid rmse:   0.88, pearson:  0.310\n",
            "[Epoch 47 ] ended with valid rmse:   0.88, pearson:  0.309\n",
            "[Epoch 48 ] ended with valid rmse:   0.88, pearson:  0.308\n",
            "[Epoch 49 ] ended with valid rmse:   0.88, pearson:  0.306\n",
            "[Epoch 50 ] ended with valid rmse:   0.88, pearson:  0.305\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}